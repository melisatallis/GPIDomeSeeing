{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.fftpack as fft\n",
    "from astropy.io import fits\n",
    "from scipy import optimize\n",
    "from poppy import zernike\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "import os\n",
    "import pytz\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telescope Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outD = 7.77010            # primary diameter (m)\n",
    "inD = 1.024               # inner M2 diameter (m)\n",
    "n = 48                    # number sample points across the screen (Not the number of subapertures)\n",
    "nacross = 43              # number of subapertures across the aperture\n",
    "pscale = outD/(nacross)   # pixel size (m) of samples in pupil plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Aperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Aperture containing zeros\n",
    "x = np.linspace(-(n)/2,(n)/2,n)*pscale \n",
    "y = np.linspace(-(n)/2,(n)/2,n)*pscale\n",
    "mg = np.meshgrid(x,y)\n",
    "ar = np.sqrt(np.sum((m**2 for m in mg)))\n",
    "ap_outer = (ar <= (7.3)/2) #slightly oversized because GPI does not correct teh boundaries well\n",
    "ap_inner = (ar <= 1.5/2)   \n",
    "\n",
    "#ap_outer = (ar <= outD/2)\n",
    "#ap_inner = (ar <= inD/2)   \n",
    "ap = (ap_outer ^ ap_inner).astype(np.float)\n",
    "\n",
    "#  Aperture containing nans\n",
    "ap_nan = np.copy(ap.astype(np.float))  \n",
    "ap_nan[np.where(ap==0)] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the spatial freq grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use to plot against spatial PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kx = fft.fftshift(fft.fftfreq(n,pscale))\n",
    "ky = fft.fftshift(fft.fftfreq(n,pscale))\n",
    "mg = np.meshgrid(kx,ky)\n",
    "kr = np.sqrt(np.sum((m**2 for m in mg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. name_list - list containing telemetry date strings\n",
    "2. fname_list - list containing path to telemetry files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/home/sda/mtallis/PhaseScripts/aotelem/Reduced/'\n",
    "save_path = '/home/sda/mtallis/Results/c_Eri/'\n",
    "dstr = time.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sda/mtallis/samples/c_Eri_samples.txt','r') as f:\n",
    "    sample = f.read().splitlines() #outputs as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname_list = list()\n",
    "name_list = list()\n",
    "\n",
    "for i in sample:\n",
    "    for root, dirs, files in os.walk(rootdir):\n",
    "        for name in files:\n",
    "            (base,ext) = os.path.splitext(name)\n",
    "            if (ext in ('.fits')) and (i in base):\n",
    "                full_name = os.path.join(root,name)\n",
    "                #print(full_name)\n",
    "                fname_list.append(full_name)  \n",
    "                name_list.append(base[11:-12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. processs_phase - Imports .fits & removes static aberrations in each phase  \n",
    "2. radialProfile - Computes mean inside each radial bin starting from center\n",
    "3. sp_power_spec - Computes time average of 2d DFT^2  \n",
    "4. temp_power_spec - Computes actuator timeseries DFT^2 and averages over aperture\n",
    "5. linear fit - fits a power law to psd. Behaves like a line in loglog space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phase(filepath):\n",
    "\n",
    "    hdulist = fits.open(filepath,memmap=True)\n",
    "    phase = hdulist[0].data.astype('float')\n",
    "    avg_phase = np.nanmean(phase*ap_nan,axis=0)  # used to find average zernikes \n",
    "\n",
    "    # remove zernikes form cube\n",
    "    z_basis = zernike.zernike_basis_faster(nterms= 6, npix = 48)\n",
    "    z_coeff = zernike.opd_expand_nonorthonormal(avg_phase, aperture=ap, nterms=6)\n",
    "    thin_lens = np.sum(z_coeff[:,None,None]*z_basis[:,:,:],axis=0)\n",
    "\n",
    "    c_phase = (phase - thin_lens[None,:,:])*ap_nan\n",
    "    c_phase[np.isnan(c_phase)]=0.\n",
    "    \n",
    "    return c_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radialProfile(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the avearge radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Calculate the indices from the image\n",
    "    y,x = np.indices((image.shape)) # first determine radii of all pixels\n",
    "    \n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "     \n",
    "    r = np.hypot(x - center[0], y - center[1]).astype(np.int) \n",
    "    \n",
    "    n = np.bincount(r.ravel())\n",
    "    sy = np.bincount(r.ravel(), image.ravel())\n",
    "    mean = sy/n\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_power_spec(phase):    \n",
    "    \n",
    "    timesteps, phx, phy = phase.shape \n",
    "    phFT = np.zeros((timesteps,phx,phy), dtype=complex)\n",
    "    for t in np.arange(timesteps):\n",
    "        phFT[t,:,:] = fft.fftshift(fft.fft2(phase[t,:,:]))*2.0/ap.sum()\n",
    "    print('Done with FT')\n",
    "    \n",
    "    # compute 2d psd cube\n",
    "    psd2D = np.zeros((timesteps, phx, phy),dtype=float)\n",
    "    for k in np.arange(phx):\n",
    "        for l in np.arange(phy):\n",
    "            psd2D[:,k,l] = np.square(np.abs(phFT[:,k,l]))\n",
    "    \n",
    "    avg_psd2D = np.mean(psd2D, axis=0)\n",
    "    print('Done with PSD')    \n",
    "    \n",
    "    # compute radial average of 2d psd cube and frequency\n",
    "    avg_psd1D =  radialProfile(avg_psd2D)\n",
    "    \n",
    "    return avg_psd1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_power_spec(Y,sample_spacing):\n",
    "    \n",
    "    n = len(Y)\n",
    "    dT = sample_spacing\n",
    "\n",
    "    w = signal.blackman(n)\n",
    "    P = np.fft.rfft(Y*w)\n",
    "    norm = 2.0/n\n",
    "    P = P * norm\n",
    "\n",
    "    P2 = np.square(np.abs(P))\n",
    "    k = np.fft.rfftfreq(n,dT)\n",
    "    \n",
    "    return k,P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fit(Y,k,param):\n",
    "    \n",
    "    if param == 'time':\n",
    "        par = np.polyfit(np.log10(k[(k>1.0)]), np.log10(k[(k>1.0)]), 1)\n",
    "       \n",
    "    if param == 'space':\n",
    "        par = np.polyfit(np.log10(k[(k>1./(3.0)) & (k<1./(0.5))]), np.log10(Y[(k>1./(3.0)) & (k<1./(0.5))]), 1)\n",
    "    \n",
    "    slope = par[0]\n",
    "    intercept = par[1]\n",
    "    return slope,intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define spatial frequencies (34 bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = radialProfile(kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store spatial PSD values in DataFrame for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sp_psd = pd.DataFrame(columns = name_list)\n",
    "\n",
    "i=0\n",
    "for file in fname_list:\n",
    "    print(file)\n",
    "    print(name_list[i])\n",
    "    y_2D = process_phase(file)\n",
    "    y_psd = sp_power_spec(y_2D)\n",
    "    df_sp_psd[name_list[i]] = y_psd\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp_psd.to_csv(save_path+'sp_psd'+'_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store temporal PSD values in DataFrame for later analysis.\n",
    "Key = 'telemetry date'\n",
    "columns = 'kt' & 't_psd' (Note varying timeseries lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterables = [name_list,['dts','kt','t_psd']]\n",
    "index = pd.MultiIndex.from_product(iterables)\n",
    "df_t_psd = pd.DataFrame(columns = index)\n",
    "\n",
    "i=0\n",
    "for file in fname_list:\n",
    "    y_2D = process_phase(file)\n",
    "    y_1D = np.mean(y_2D,axis=(1,2))\n",
    "    kt,y_psd = temp_power_spec(y_1D,.001)\n",
    "    y_smoothed = 10**signal.savgol_filter(np.log10(y_psd), 101, 5)\n",
    "    #df_t_psd[name_list[i],'dts'] = pd.to_datetime(name_list[i],format='%Y.%m.%d_%H.%M.%S',utc=True)\n",
    "    df_t_psd[name_list[i],'kt'] = pd.Series(kt)\n",
    "    df_t_psd[name_list[i],'t_psd'] = pd.Series(y_smoothed)\n",
    "    print(name_list[i])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_t_psd.to_csv(save_path+'t_psd'+'_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping of samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in spatial or temporal psd samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp_psd = pd.read_csv(save_path+'sp_psd_20190303.txt',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put dates into night groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname_list':fname_list,'name_list':name_list})\n",
    "df['dts'] = pd.to_datetime(df['name_list'],format='%Y.%m.%d_%H.%M.%S',utc=True)\n",
    "df['delta_t'] = df['dts']-df['dts'].shift(1)\n",
    "df.loc[0,'delta_t'] = pd.Timedelta(0)\n",
    "\n",
    "def bin_f(row):\n",
    "    if row['delta_t'] > pd.Timedelta('20H'):\n",
    "        return row['dts'].date()\n",
    "    \n",
    "df['bin']=df.apply(bin_f,axis = 1)\n",
    "df.loc[0:1,'bin']=df.loc[0,'dts'].date()\n",
    "df['bin']=df['bin'].fillna(method='ffill')\n",
    "g_df = df.groupby('bin')g_df = df.groupby('bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the average psd measured in each night window. Column names contain date at the start of the night "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_sp_psd = pd.DataFrame()\n",
    "df_avg_sp_psd['k'] = k\n",
    "\n",
    "for name,group in g_df:\n",
    "    df_avg_sp_psd.loc[:,str(name)] = df_sp_psd.loc[:,group['name_list'].tolist()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit power law to avg PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear_fit_psd = pd.DataFrame(columns=['sp_psd','t_psd'])\n",
    "df_linear_fit_psd['sp_psd'] = df_avg_sp_psd.apply(linear_fit, k=k, param='space',axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting of PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, intercept = linear_fit(kt,y_smoothed,time = True, space = False)\n",
    "    plt.loglog(kt,y_smoothed, label = name_list[i])\n",
    "    plt.loglog(kt[kt>1.0], (10**intercept)*kt[kt>1.]**-1*m)\n",
    "\n",
    "plt.grid(axis='both')\n",
    "plt.axvline(x=1)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
