{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.fftpack as fft\n",
    "from astropy.io import fits\n",
    "from scipy import optimize\n",
    "from scipy import signal\n",
    "import poppy\n",
    "import gpipsfs\n",
    "import os\n",
    "import pytz\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "from matplotlib import rcParams\n",
    "rc('xtick', labelsize=15) \n",
    "rc('ytick', labelsize=15)\n",
    "\n",
    "rc('axes', labelsize=20) \n",
    "rc('axes', linewidth=1)\n",
    "\n",
    "rcParams['axes.titlesize'] = 15\n",
    "rcParams['legend.fontsize'] = 15\n",
    "rcParams['patch.linewidth'] = 1\n",
    "#rcParams['axes.titlepad'] = 30\n",
    "rcParams['axes.labelpad'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telescope Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outD = 7.77010            # primary diameter (m)\n",
    "inD = 1.024               # inner M2 diameter (m)\n",
    "n = 48                    # number sample points across the screen (Not the number of subapertures)\n",
    "nacross = 43              # number of subapertures across the aperture\n",
    "pscale = outD/(nacross)   # pixel size (m) of samples in pupil plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Aperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Aperture containing zeros\n",
    "x = np.linspace(-(n)/2,(n)/2,n)*pscale \n",
    "y = np.linspace(-(n)/2,(n)/2,n)*pscale\n",
    "mg = np.meshgrid(x,y)\n",
    "ar = np.sqrt(np.sum((m**2 for m in mg)))\n",
    "ap_outer = (ar <= (7.3)/2) #mask is slightly oversized because GPI does not correct the boundaries well\n",
    "ap_inner = (ar <= 1.5/2)   \n",
    "\n",
    "#ap_outer = (ar <= outD/2)\n",
    "#ap_inner = (ar <= inD/2)   \n",
    "ap = (ap_outer ^ ap_inner).astype(np.float)\n",
    "\n",
    "#  Aperture containing nans\n",
    "ap_nan = np.copy(ap.astype(np.float))  \n",
    "ap_nan[np.where(ap==0)] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the spatial freq grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use to plot against spatial PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kx = fft.fftshift(fft.fftfreq(n,pscale))\n",
    "ky = fft.fftshift(fft.fftfreq(n,pscale))\n",
    "mg = np.meshgrid(kx,ky)\n",
    "kr = np.sqrt(np.sum((m**2 for m in mg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. name_list - list containing telemetry date strings\n",
    "2. fname_list - list containing path to telemetry files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_manager(desktop_name):\n",
    "    \n",
    "    if desktop_name == 'gpi_cruncher':\n",
    "        rootdir = '/home/sda/mtallis/PhaseScripts/aotelem/Reduced/'\n",
    "        save_path = '/home/sda/mtallis/Results/c_Eri/'\n",
    "        samples_path = '/home/sda/mtallis/samples/c_Eri_samples.txt'\n",
    "    \n",
    "    if desktop_name == 'kipac':\n",
    "        rootdir = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        save_path = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Results/journal_figures/'\n",
    "        samples_path = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/datatables/c_Eri_samples.txt'\n",
    "        \n",
    "    if desktop_name == 'laptop':\n",
    "        rootdir = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        save_path = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        samples_path = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/c_Eri_samples.txt'\n",
    "\n",
    "    dstr = time.strftime('%Y%m%d')\n",
    "    return rootdir,save_path, samples_path, dstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootdir, save_path, samples_path, dstr = path_manager('gpi_cruncher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(samples_path,'r') as f:\n",
    "    sample = f.read().splitlines() #outputs as a list of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use with gpi cruncher when images need to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname_list = list()\n",
    "name_list = list()\n",
    "\n",
    "for i in sample:\n",
    "    for root, dirs, files in os.walk(rootdir):\n",
    "        for name in files:\n",
    "            (base,ext) = os.path.splitext(name)\n",
    "            if (ext in ('.fits')) and (i in base):\n",
    "                full_name = os.path.join(root,name)\n",
    "                #print(full_name)\n",
    "                fname_list.append(full_name)  \n",
    "                name_list.append(base[11:-12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. processs_phase - Imports .fits & removes static aberrations in each phase  \n",
    "2. radialProfile - Computes mean inside each radial bin starting from center\n",
    "3. sp_power_spec - Computes time average of 2d DFT^2  \n",
    "4. temp_power_spec - Computes actuator timeseries DFT^2 and averages over aperture\n",
    "5. linear fit - fits a power law to psd. Behaves like a line in loglog space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_fits(filepath):\n",
    "\n",
    "    hdulist = fits.open(filepath,memmap=True)\n",
    "    phase = hdulist[0].data.astype('float')\n",
    "\n",
    "    return phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_zernikes(phase):\n",
    "    \n",
    "    m1 = gpipsfs.GeminiPrimary().sample(npix=48)\n",
    "    avg_phase = np.mean(phase*m1,axis=0)\n",
    "    \n",
    "    z_basis = poppy.zernike.zernike_basis_faster(nterms= 6, npix = 48)\n",
    "    z_coeff = poppy.zernike.opd_expand_nonorthonormal(avg_phase, aperture=m1, nterms=6)\n",
    "    thin_lens = np.sum(z_coeff[:,None,None]*z_basis[:,:,:],axis=0)\n",
    "    c_phase = (phase - thin_lens[None,:,:])*m1\n",
    "    c_phase[np.isnan(c_phase)]=0.\n",
    "\n",
    "    return c_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_modal_basis(phase):\n",
    "    \n",
    "    timesteps, phx, phy = phase.shape \n",
    "    ap = gpipsfs.GPI_Apodizer().sample(npix = phx) # windowing function to smooth-out hard edges of aperture\n",
    "    \n",
    "    phFT = np.zeros((timesteps,phx,phy), dtype=complex)\n",
    "    for t in np.arange(timesteps):\n",
    "        phFT[t,:,:] = np.fft.fftshift(fft.fft2(phase[t,:,:]*ap)/np.sqrt(ap.sum()))\n",
    "    print('Done with FT')\n",
    "\n",
    "    # remove static aberrations from the signal \n",
    "    mft = np.mean(phFT,axis = 0) \n",
    "    phFT = phFT - mft[None,:,:]  \n",
    "    \n",
    "    return phFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sp_power_spec(phFT):    \n",
    "    \n",
    "    timesteps, phx, phy = phFT.shape\n",
    "    \n",
    "    # compute 2d psd cube\n",
    "    psd2D = np.zeros((timesteps, phx, phy),dtype=float)\n",
    "    for k in np.arange(phx):\n",
    "        for l in np.arange(phy):\n",
    "            psd2D[:,k,l] = np.square(np.abs(phFT[:,k,l]))\n",
    "    \n",
    "    varpsd = np.sum(psd2D, axis=0)\n",
    "    print('Done with PSD')    \n",
    "    \n",
    "    # compute radial average of 2d psd cube and frequency\n",
    "    psd1D =  radialProfile(varpsd)\n",
    "    \n",
    "    return psd1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_phase(filepath):\n",
    "\n",
    "    hdulist = fits.open(filepath,memmap=True)\n",
    "    phase = hdulist[0].data.astype('float')\n",
    "    avg_phase = np.nanmean(phase*ap_nan,axis=0)  # used to find average zernikes \n",
    "\n",
    "    # remove zernikes form cube\n",
    "    z_basis = zernike.zernike_basis_faster(nterms= 6, npix = 48)\n",
    "    z_coeff = zernike.opd_expand_nonorthonormal(avg_phase, aperture=ap, nterms=6)\n",
    "    thin_lens = np.sum(z_coeff[:,None,None]*z_basis[:,:,:],axis=0)\n",
    "\n",
    "    c_phase = (phase - thin_lens[None,:,:])*ap_nan\n",
    "    c_phase[np.isnan(c_phase)]=0.\n",
    "    \n",
    "    return c_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def radialProfile(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the avearge radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Calculate the indices from the image\n",
    "    y,x = np.indices((image.shape)) # first determine radii of all pixels\n",
    "    \n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "     \n",
    "    r = np.hypot(x - center[0], y - center[1]).astype(np.int) \n",
    "    \n",
    "    n = np.bincount(r.ravel())\n",
    "    sy = np.bincount(r.ravel(), image.ravel())\n",
    "    mean = sy/n\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sp_power_spec(phase):    \n",
    "    \n",
    "    timesteps, phx, phy = phase.shape \n",
    "    phFT = np.zeros((timesteps,phx,phy), dtype=complex)\n",
    "    for t in np.arange(timesteps):\n",
    "        phFT[t,:,:] = fft.fftshift(fft.fft2(phase[t,:,:]))*2.0/ap.sum()\n",
    "    print('Done with FT')\n",
    "    \n",
    "    # compute 2d psd cube\n",
    "    psd2D = np.zeros((timesteps, phx, phy),dtype=float)\n",
    "    for k in np.arange(phx):\n",
    "        for l in np.arange(phy):\n",
    "            psd2D[:,k,l] = np.square(np.abs(phFT[:,k,l]))\n",
    "    \n",
    "    avg_psd2D = np.mean(psd2D, axis=0)\n",
    "    print('Done with PSD')    \n",
    "    \n",
    "    # compute radial average of 2d psd cube and frequency\n",
    "    avg_psd1D =  radialProfile(avg_psd2D)\n",
    "    \n",
    "    return avg_psd1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temp_power_spec(Y,sample_spacing):\n",
    "    \n",
    "    n = len(Y)\n",
    "    dT = sample_spacing\n",
    "\n",
    "    w = signal.blackman(n)\n",
    "    P = np.fft.rfft(Y*w)\n",
    "    norm = 2.0/n\n",
    "    P = P * norm\n",
    "\n",
    "    P2 = np.square(np.abs(P))\n",
    "    #k = np.fft.rfftfreq(n,dT)\n",
    "    \n",
    "    return P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_fit(k,Y,low_b,up_b):\n",
    "\n",
    "    par = np.polyfit(np.log10(k[(k>low_b) & (k<up_b)]), np.log10(Y[(k>low_b) & (k<up_b)]), 1)\n",
    "    slope = par[0]\n",
    "    intercept = par[1]\n",
    "    \n",
    "    return slope, intercept   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def psd_area(k,Y,b):\n",
    "    \n",
    "    x = k[k<b]\n",
    "    y = Y[k<b]\n",
    "    area = np.trapz(y,x)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate PSDs from telemetry files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define spatial frequencies (34 bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = radialProfile(kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store spatial PSD values in DataFrame for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sp_psd = pd.DataFrame(columns = name_list)\n",
    "\n",
    "i=0\n",
    "for file in fname_list:\n",
    "    print(file)\n",
    "    print(name_list[i])\n",
    "    y_2D = process_phase(file)\n",
    "    y_psd = sp_power_spec(y_2D)\n",
    "    df_sp_psd[name_list[i]] = y_psd\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sp_psd.to_csv(save_path+'sp_psd'+'_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store temporal PSD values in DataFrame for later analysis.\n",
    "Key = 'telemetry date'\n",
    "columns = 'kt' & 't_psd' (Note varying timeseries lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_t_psd = pd.DataFrame()\n",
    "\n",
    "i=0\n",
    "for file in fname_list[0:2]:\n",
    "    y_2D = process_phase(file)\n",
    "    y_1D = np.mean(y_2D,axis=(1,2))\n",
    "    y_psd = temp_power_spec(y_1D,.001)\n",
    "    y_smoothed = 10**signal.savgol_filter(np.log10(y_psd), 101, 5)\n",
    "    #df_t_psd[name_list[i],'dts'] = pd.to_datetime(name_list[i],format='%Y.%m.%d_%H.%M.%S',utc=True)\n",
    "    new_df = pd.DataFrame({name_list[i]:y_smoothed})\n",
    "    df_t_psd = pd.concat([df_t_psd,new_df],axis=1)\n",
    "    print(name_list[i])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_t_psd.to_csv(save_path+'t_psd'+'_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping of samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in spatial or temporal psd samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sp_psd = pd.read_csv(rootdir+'c_Eri_sp_psd_20190318.txt',index_col=0)\n",
    "df_t_psd = pd.read_csv(rootdir+'c_Eri_t_psd_20190318.txt',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put dates into night groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname_list':fname_list,'name_list':name_list})\n",
    "df['dts'] = pd.to_datetime(df['name_list'],format='%Y.%m.%d_%H.%M.%S',utc=True)\n",
    "df['delta_t'] = df['dts']-df['dts'].shift(1)\n",
    "df.loc[0,'delta_t'] = pd.Timedelta(0)\n",
    "\n",
    "def bin_f(row):\n",
    "    if row['delta_t'] > pd.Timedelta('20H'):\n",
    "        return row['dts'].date()\n",
    "    \n",
    "df['bin']=df.apply(bin_f,axis = 1)\n",
    "df.loc[0:1,'bin']=df.loc[0,'dts'].date()\n",
    "df['bin']=df['bin'].fillna(method='ffill')\n",
    "g_df = df.groupby('bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the average psd measured in each night window. Column names contain date at the start of the night "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_avg_sp_psd = pd.DataFrame()\n",
    "\n",
    "for name,group in g_df:\n",
    "    df_avg_sp_psd.loc[:,str(name)] = df_sp_psd.loc[:,group['name_list'].tolist()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_avg_sp_psd.to_csv(save_path+'avg_sp_psd_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_avg_t_psd = pd.DataFrame()\n",
    "\n",
    "for name,group in g_df:\n",
    "    df_avg_t_psd.loc[:,str(name)] = df_t_psd.loc[:,group['name_list'].tolist()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_avg_t_psd.to_csv(save_path+'avg_t_psd_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in avg psd dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_avg_sp_psd = pd.read_csv(rootdir+'c_Eri_avg_sp_psd_20190318.txt',index_col=0)\n",
    "df_avg_t_psd = pd.read_csv(rootdir+'c_Eri_avg_t_psd_20190318.txt',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit power law to avg PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "df_psd_results = pd.DataFrame(columns=['sp_psd_slope','sp_psd_int','sp_psd_area','t_psd_slope','t_psd_int','t_psd_area'], index = df_avg_sp_psd.columns)\n",
    "df_psd_results\n",
    "\n",
    "for i in df_avg_sp_psd.columns:\n",
    "    y = df_avg_sp_psd[i]\n",
    "    x = radialProfile(kr)\n",
    "    df_psd_results.loc[i,['sp_psd_slope','sp_psd_int']] = linear_fit(x,y,.33,1)\n",
    "    df_psd_results.loc[i,'sp_psd_area'] = psd_area(x,y,2.8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_psd_results.sort_values(by ='sp_psd_int',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in df_avg_t_psd.columns:\n",
    "    y = df_avg_t_psd[i].dropna()\n",
    "    x = fft.fftfreq(len(y),.001)\n",
    "    df_psd_results.loc[i,['t_psd_slope','t_psd_int']] = linear_fit(x,y,2,30)\n",
    "    df_psd_results.loc[i,'t_psd_area'] = psd_area(x,y,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_psd_results.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot PSDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial PSD plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fit_x = np.linspace(0.33,1,20)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "\n",
    "for key in df_psd_results.index:\n",
    "    y = df_avg_sp_psd[key]\n",
    "    m,yint = linear_fit(k,y,0.33,1)\n",
    "    ax.loglog(k,y,label = key+ ' yint =' +str (yint.round(2)))\n",
    "    #ax.loglog(fit_x,10**yint*fit_x**m)\n",
    "    \n",
    "ax.set_xlim(.1,3)\n",
    "fig.legend(loc=1,fontsize=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "x = radialProfile(kr)\n",
    "sp_bounds = (x>0.33) & (x<1)\n",
    "fit_x = np.linspace(0.33,1,20)\n",
    "\n",
    "y1 = df_avg_sp_psd['2016-09-18']\n",
    "m1,int1 = linear_fit(x,y1,0.33,1)\n",
    "print(m1,int1)\n",
    "\n",
    "y2 = df_avg_sp_psd['2016-09-21']\n",
    "m2,int2 = linear_fit(x,y2,0.33,1) \n",
    "print(m2,int2)\n",
    "\n",
    "#plt.loglog(x,10**int2*x**-3.67,'silver',linestyle='-.')\n",
    "plt.loglog(x,y1,'blue',lw=1,label = '2016-09-18 ; delT = .1')\n",
    "plt.loglog(x,y2,'red',lw=1, label = '2016-09-21 ; delT = 1.1')\n",
    "\n",
    "plt.loglog(fit_x,10**int1*fit_x**m1,'b|', marker=(2,0,-40),markersize=7)\n",
    "plt.loglog(fit_x,10**int2*fit_x**m2,'r|',lw=1,marker=(2,0,-40),markersize=7)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(axis='both')\n",
    "plt.xlim(.1,3)\n",
    "#plt.ylim(3*10**-4,8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal PSD plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# spatial PSD calculations\n",
    "sp_x = radialProfile(kr)\n",
    "sp_fit_x = np.linspace(0.33,1,20)\n",
    "\n",
    "sp_y1 = df_avg_sp_psd['2016-09-18']\n",
    "sp_m1,sp_int1 = linear_fit(sp_x,sp_y1,0.33,1)\n",
    "print(sp_m1,sp_int1)\n",
    "\n",
    "sp_y2 = df_avg_sp_psd['2016-09-21']\n",
    "sp_m2,sp_int2 = linear_fit(sp_x,sp_y2,0.33,1) \n",
    "print(sp_m2,sp_int2)\n",
    "\n",
    "#sp_y3 = df_avg_sp_psd['2016-09-21']\n",
    "#sp_m3,sp_int3 = linear_fit(sp_x,sp_y3,0.33,1) \n",
    "#print(sp_m3,sp_int3)\n",
    "\n",
    "# temporal PSD calculations\n",
    "t_y1 = df_avg_t_psd['2016-09-18']\n",
    "t_x1 = fft.rfftfreq(len(t_y1),.001)\n",
    "t_fit_x= np.linspace(3.0,30.0,2)\n",
    "t_m1,t_int1 = linear_fit(t_x1,t_y1,3.0,30.0) \n",
    "print(t_m1,t_int1)\n",
    "\n",
    "t_y2 = df_avg_t_psd['2016-09-21']\n",
    "t_x2 = fft.rfftfreq(len(t_y2),.001)\n",
    "t_m2,t_int2 = linear_fit(t_x2,t_y2,3.0,40.0) \n",
    "print(t_m2,t_int2)\n",
    "\n",
    "#t_y3 = df_avg_t_psd['2016-09-21']\n",
    "#t_x3 = fft.rfftfreq(len(t_y3),.001)\n",
    "#t_m3,t_int3 = linear_fit(t_x3,t_y3,3.0,40.0) \n",
    "#print(t_m3,t_int3)\n",
    "\n",
    "#Plotting in figure \n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(18,6))\n",
    "\n",
    "ax1.loglog(sp_x,sp_y1,'k:',lw=2,alpha = 1,label ='09/18/2016 PSD')\n",
    "ax1.loglog(sp_x,sp_y3,'k--',lw=2,alpha = 1,label ='09/21/2016 PSD')\n",
    "ax1.loglog(sp_x,sp_y2,'k',lw=2,alpha = 1,label ='12/19/2015 PSD')\n",
    "ax1.loglog(sp_fit_x,10**sp_int1*sp_fit_x**sp_m1,'dodgerblue',lw=4,label ='09/18/2016 fit')\n",
    "#ax1.loglog(sp_fit_x,10**sp_int3*sp_fit_x**sp_m3,'orange',lw=2, label ='09/21/2016 fit')\n",
    "ax1.loglog(sp_fit_x,10**sp_int2*sp_fit_x**sp_m2,'crimson',lw=4, label ='12/19/2015 fit')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='both',which = 'both',direction='in', width=1,top=True,right=True,length = 10, pad =15)\n",
    "ax1.set_ylabel(r'PSD [$\\frac{\\mu m^2}{m^{-1}}$]')\n",
    "ax1.set_xlabel(r'f [$m^{-1}$]')\n",
    "ax1.set_xlim(.1,3)\n",
    "\n",
    "ax1.annotate('slope = ' + str(sp_m1.round(2)),[.18,1.1*10**-2],fontsize =15,color = 'dodgerblue') # fit for 9/18/2018\n",
    "ax1.annotate('slope = ' + str(sp_m2.round(2)),[.9,3*10**-3],fontsize =15,color = 'crimson') # fit for 9/21/2018\n",
    ".15,1.1*10**-2\n",
    "ax2.loglog(t_x1,t_y1,'k:',lw=2,alpha = 1,label ='09/18/2016 PSD')\n",
    "ax2.loglog(t_x2,t_y2,'k',lw=2,alpha = 1,label ='09/21/2016 PSD')\n",
    "ax2.loglog(t_fit_x,10**t_int1*t_fit_x**t_m1,'dodgerblue',lw=4,label ='09/18/2016 fit')\n",
    "ax2.loglog(t_fit_x,10**t_int2*t_fit_x**t_m2,'crimson',lw=4, label ='09/21/2016 fit')\n",
    "\n",
    "ax2.annotate('slope = ' + str(t_m1.round(2)),[3,1.1*10**-8],fontsize =15,color = 'dodgerblue')\n",
    "ax2.annotate('slope = ' + str(t_m2.round(2)),[11,5*10**-7],fontsize =15,color = 'crimson')\n",
    "15,5*10**-7\n",
    "ax2.legend()\n",
    "ax2.tick_params(axis='both',which = 'both',direction='in', width=1,top=True,right=True,length = 10, pad =15)\n",
    "ax2.set_ylabel(r'PSD [$\\frac{\\mu m^2}{Hz}$]')\n",
    "ax2.set_xlabel(r'f [$Hz$]')\n",
    "ax2.set_xlim(.1,400)\n",
    "#ax2.set_ylim(10**-9,10**-4)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plt.savefig(save_path+'c_Eri_PSD_'+dstr+'.eps',dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting of PSDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick check of standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phase = import_fits(fname_list[100])\n",
    "m1 = gpipsfs.GeminiPrimary().sample(npix=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_phase = np.std(phase*m1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.imshow(std_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
