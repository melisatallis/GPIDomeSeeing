{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.fftpack as fft\n",
    "import poppy\n",
    "import gpipsfs\n",
    "import pytz\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import welch\n",
    "from astropy.io import fits\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telescope dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outD = 7.77010            # primary diameter (m)\n",
    "inD = 1.024               # inner M2 diameter (m)\n",
    "n = 48                    # number sample points across the screen (Not the number of subapertures)\n",
    "nacross = 43              # number of subapertures across the aperture\n",
    "pscale = outD/(nacross)   # pixel size (m) of samples in pupil plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_manager(desktop_name):\n",
    "    \n",
    "    if desktop_name == 'gpi_cruncher':\n",
    "        rootdir = '/home/sda/mtallis/PhaseScripts/aotelem/Reduced/'\n",
    "        save_path = '/home/sda/mtallis/Results/datatables/'\n",
    "        samples_path = '/home/sda/mtallis/samples/phase_samples_20181119.txt'\n",
    "        #rootdir = '/home/sda/mtallis/PhaseScripts/aotelem/Reduced/'\n",
    "        #save_path = '/home/sda/mtallis/Results/c_Eri/'\n",
    "        #samples_path = '/home/sda/mtallis/samples/c_Eri_samples.txt'\n",
    "    \n",
    "    if desktop_name == 'kipac':\n",
    "        rootdir = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        save_path = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        samples_path = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/datatables/'\n",
    "        \n",
    "    if desktop_name == 'laptop':\n",
    "        rootdir = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        save_path = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        samples_path = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/c_Eri_samples.txt'\n",
    "\n",
    "    dstr = time.strftime('%Y%m%d')\n",
    "    return rootdir,save_path, samples_path, dstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir, save_path, samples_path, dstr = path_manager('gpi_cruncher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(samples_path,'r') as f:\n",
    "    sample = f.read().splitlines() #outputs as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname_list = list()\n",
    "name_list = list()\n",
    "\n",
    "for i in sample:\n",
    "    for root, dirs, files in os.walk(rootdir):\n",
    "        for name in files:\n",
    "            (base,ext) = os.path.splitext(name)\n",
    "            if (ext in ('.fits')) and (i in base):\n",
    "                full_name = os.path.join(root,name)\n",
    "                #print(full_name)\n",
    "                fname_list.append(full_name)  \n",
    "                name_list.append(base[11:-12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_phase(filepath):\n",
    "\n",
    "    hdulist = fits.open(filepath,memmap=True)\n",
    "    phase = hdulist[0].data.astype('float')\n",
    "    avg_phase = np.nanmean(phase*ap_nan,axis=0)  # used to find average zernikes \n",
    "\n",
    "    # remove zernikes form cube\n",
    "    z_basis = poppy.zernike.zernike_basis_faster(nterms= 6, npix = 48)\n",
    "    z_coeff = poppy.zernike.opd_expand_nonorthonormal(avg_phase, aperture=ap, nterms=6)\n",
    "    thin_lens = np.sum(z_coeff[:,None,None]*z_basis[:,:,:],axis=0)\n",
    "\n",
    "    c_phase = (phase - thin_lens[None,:,:])*ap_nan\n",
    "    c_phase[np.isnan(c_phase)]=0.\n",
    "    \n",
    "    return c_phase\n",
    "\n",
    "def power_law_fit(k,Y,low_b,up_b):\n",
    "\n",
    "    par = np.polyfit(np.log10(k[(k>low_b) & (k<up_b)]), np.log10(Y[(k>low_b) & (k<up_b)]), 1)\n",
    "    exp = par[0]\n",
    "    amp = par[1]\n",
    "    print(exp,amp)\n",
    "    return exp, amp   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execute program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_t_psd = pd.DataFrame(columns = name_list)\n",
    "df_t_freq = pd.DataFrame(columns = name_list)\n",
    "\n",
    "i=0\n",
    "for file in fname_list[0:2]:\n",
    "    print(name_list[i])\n",
    "    y_2D = process_phase(file)\n",
    "    y_1D = np.mean(y_2D,axis=(1,2))\n",
    "    f, psd = welch(y_1D,\n",
    "               fs=.001,  # sample rate\n",
    "               window='blackman',   # apply a Hanning window before taking the DFT\n",
    "               nperseg=1024,        # compute periodograms of 256-long segments of x\n",
    "               detrend='constant') # detrend x by subtracting the mean\n",
    "    df_t_psd[name_list[i]] = pd.Series(f)\n",
    "    df_t_freq[name_list[i]] = pd.Series(psd)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_t_psd.to_csv(save_path+'t_psd'+'_'+dstr+'.txt')\n",
    "df_t_freq.to_csv(save_path+'t_freq'+'_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname_list':fname_list,'name_list':name_list})\n",
    "df['dts'] = pd.to_datetime(df['name_list'],format='%Y.%m.%d_%H.%M.%S',utc=True)\n",
    "df['delta_t'] = df['dts']-df['dts'].shift(1)\n",
    "df.loc[0,'delta_t'] = pd.Timedelta(0)\n",
    "\n",
    "def bin_f(row):\n",
    "    if row['delta_t'] > pd.Timedelta('20H'):\n",
    "        return row['dts'].date()\n",
    "    \n",
    "df['bin']=df.apply(bin_f,axis = 1)\n",
    "df.loc[0:1,'bin']=df.loc[0,'dts'].date()\n",
    "df['bin']=df['bin'].fillna(method='ffill')\n",
    "g_df = df.groupby('bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the average psd measured in each night window. Column names contain date at the start of the night "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_avg_t_psd = pd.DataFrame()\n",
    "\n",
    "for name,group in g_df:\n",
    "    df_avg_t_psd.loc[:,str(name)] = df_t_psd.loc[:,group['name_list'].tolist()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_avg_t_freq = pd.DataFrame()\n",
    "\n",
    "for name,group in g_df:\n",
    "    df_avg_t_freq.loc[:,str(name)] = df_t_freq.loc[:,group['name_list'].tolist()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save grouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_avg_t_psd.to_csv(save_path+'avg_t_psd_'+dstr+'.txt')\n",
    "df_avg_t_freq.to_csv(save_path+'avg_t_freq_'+dstr+'.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
