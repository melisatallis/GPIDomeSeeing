{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.fftpack as fft\n",
    "import poppy\n",
    "import gpipsfs\n",
    "import pytz\n",
    "import time\n",
    "import re\n",
    "\n",
    "from scipy import signal\n",
    "from astropy.io import fits\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telescope dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outD = 7.77010            # primary diameter (m)\n",
    "inD = 1.024               # inner M2 diameter (m)\n",
    "n = 48                    # number sample points across the screen (Not the number of subapertures)\n",
    "nacross = 43              # number of subapertures across the aperture\n",
    "pscale = outD/(nacross)   # pixel size (m) of samples in pupil plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make spatial frequency grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kx = fft.fftshift(fft.fftfreq(n,pscale))\n",
    "ky = fft.fftshift(fft.fftfreq(n,pscale))\n",
    "mg = np.meshgrid(kx,ky)\n",
    "kr = np.sqrt(np.sum((m**2 for m in mg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. name_list - list containing telemetry date strings\n",
    "2. fname_list - list containing path to telemetry files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 =  '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Reduced/20160229/aored_When_2016.2.29_5.33.19_poldm_phase.fits'\n",
    "file2 =  '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Reduced/20160227/aored_When_2016.2.27_0.2.8_poldm_phase.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_manager(desktop_name):\n",
    "    \n",
    "    if desktop_name == 'gpi_cruncher':\n",
    "        rootdir = '/home/sda/mtallis/PhaseScripts/aotelem/Reduced/'\n",
    "        save_path = '/home/sda/mtallis/Results/c_Eri/'\n",
    "        samples_path = '/home/sda/mtallis/samples/c_Eri_samples.txt'\n",
    "    \n",
    "    if desktop_name == 'kipac':\n",
    "        rootdir = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        save_path = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        samples_path = '/Users/MelisaT/Documents/Research/GPIDomeSeeing/data/datatables/'\n",
    "        \n",
    "    if desktop_name == 'laptop':\n",
    "        rootdir = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        save_path = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/'\n",
    "        samples_path = '/Users/melisatallis/Documents/Research/GPIDomeSeeing/data/Results/c_Eri/c_Eri_samples.txt'\n",
    "\n",
    "    dstr = time.strftime('%Y%m%d')\n",
    "    return rootdir,save_path, samples_path, dstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir, save_path, samples_path, dstr = path_manager('kipac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(samples_path,'r') as f:\n",
    "    sample = f.read().splitlines() #outputs as a list of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use when fits files are available, which are typically stored in GPI cruncher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_list = list()\n",
    "name_list = list()\n",
    "\n",
    "for i in sample:\n",
    "    for root, dirs, files in os.walk(rootdir):\n",
    "        for name in files:\n",
    "            (base,ext) = os.path.splitext(name)\n",
    "            if (ext in ('.fits')) and (i in base):\n",
    "                full_name = os.path.join(root,name)\n",
    "                #print(full_name)\n",
    "                fname_list.append(full_name)  \n",
    "                name_list.append(base[11:-12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. processs_phase - Imports .fits & removes static aberrations in each phase  \n",
    "2. radialProfile - Computes mean inside each radial bin starting from center\n",
    "3. sp_power_spec - Computes time average of 2d DFT^2  \n",
    "4. temp_power_spec - Computes actuator timeseries DFT^2 and averages over aperture\n",
    "5. linear fit - fits a power law to psd. Behaves like a line in loglog space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_fits(filepath):\n",
    "\n",
    "    hdulist = fits.open(filepath,memmap=True)\n",
    "    phase = hdulist[0].data.astype('float')\n",
    "\n",
    "    return phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zernikes(phase):\n",
    "    \n",
    "    m1 = gpipsfs.GeminiPrimary().sample(npix=48)\n",
    "    avg_phase = np.mean(phase*m1,axis=0)\n",
    "    \n",
    "    z_basis = poppy.zernike.zernike_basis_faster(nterms= 6, npix = 48)\n",
    "    z_coeff = poppy.zernike.opd_expand_nonorthonormal(avg_phase, aperture=m1, nterms=6)\n",
    "    thin_lens = np.sum(z_coeff[:,None,None]*z_basis[:,:,:],axis=0)\n",
    "    c_phase = (phase - thin_lens[None,:,:])*m1\n",
    "    c_phase[np.isnan(c_phase)]=0.\n",
    "\n",
    "    plt.imshow(c_phase[0])\n",
    "    return c_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radialProfile(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the avearge radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Calculate the indices from the image\n",
    "    y,x = np.indices((image.shape)) # first determine radii of all pixels\n",
    "    \n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "     \n",
    "    r = np.hypot(x - center[0], y - center[1]).astype(np.int) \n",
    "    \n",
    "    n = np.bincount(r.ravel())\n",
    "    sy = np.bincount(r.ravel(), image.ravel())\n",
    "    mean = sy/n\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_modal_basis(phase):\n",
    "    \n",
    "    timesteps, phx, phy = phase.shape \n",
    "    ap = gpipsfs.GPI_Apodizer().sample(npix = phx) # windowing function to smooth-out hard edges of aperture\n",
    "    \n",
    "    phFT = np.zeros((timesteps,phx,phy), dtype=complex)\n",
    "    for t in np.arange(timesteps):\n",
    "        phFT[t,:,:] = np.fft.fftshift(fft.fft2(phase[t,:,:]*ap)/np.sqrt(ap.sum()))\n",
    "    print('Done with FT')\n",
    "\n",
    "    # remove static aberrations from the signal \n",
    "    mft = np.mean(phFT,axis = 0) \n",
    "    phFT = phFT - mft[None,:,:]  \n",
    "    \n",
    "    return phFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_power_spec(phFT):    \n",
    "    \n",
    "    timesteps, phx, phy = phFT.shape\n",
    "    \n",
    "    # compute 2d psd cube\n",
    "    psd2D = np.zeros((timesteps, phx, phy),dtype=float)\n",
    "    for k in np.arange(phx):\n",
    "        for l in np.arange(phy):\n",
    "            psd2D[:,k,l] = np.square(np.abs(phFT[:,k,l]))\n",
    "    \n",
    "    varpsd = np.sum(psd2D, axis=0)\n",
    "    print('Done with PSD')    \n",
    "    \n",
    "    # compute radial average of 2d psd cube and frequency\n",
    "    psd1D =  radialProfile(varpsd)\n",
    "    \n",
    "    return psd1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_power_spec(Y):\n",
    "    \n",
    "    n = len(Y)\n",
    "    P = np.fft.rfft(Y)\n",
    "    norm = 2.0/n\n",
    "    P = P * norm\n",
    "    P2 = np.square(np.abs(P))\n",
    "    \n",
    "    return P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fit(k,Y,low_b,up_b):\n",
    "\n",
    "    par = np.polyfit(np.log10(k[(k>low_b) & (k<up_b)]), np.log10(Y[(k>low_b) & (k<up_b)]), 1)\n",
    "    slope = par[0]\n",
    "    intercept = par[1]\n",
    "    print(slope,intercept)\n",
    "    \n",
    "    return slope, intercept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define spatial frequncy grid - has 34 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = radialProfile(kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store spatial PSD values in DataFrame for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp_psd = pd.DataFrame(columns = name_list)\n",
    "\n",
    "i=0\n",
    "for file in fname_list:\n",
    "    print(name_list[i])\n",
    "    y_2D = import_fits(file)\n",
    "    y_ft = convert_to_modal_basis(y_2D) # mFT get subtracted from fourier modes\n",
    "    y_psd = sp_power_spec(y_ft)\n",
    "    df_sp_psd[name_list[i]] = pd.Series(y_psd)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp_psd.to_csv(save_path+'sp_psd'+'_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store temporal PSD values in dataframe for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_psd = pd.DataFrame(columns = name_list)\n",
    "\n",
    "i=0\n",
    "for file in fname_list[0:2]:\n",
    "    print(name_list[i])\n",
    "    y_2D = import_fits(file)\n",
    "    c_y_2D = remove_zernikes(y_2D)\n",
    "    y_1D = np.sum(c_y_2D,axis=(1,2))\n",
    "    y_psd = temp_power_spec(y_1D)\n",
    "    y_smoothed = 10**signal.savgol_filter(np.log10(y_psd), 101, 5)\n",
    "    df_t_psd[name_list[i]] = pd.Series(y_smooth)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_psd.to_csv(save_path+'t_psd'+'_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Samples by night observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname_list':fname_list,'name_list':name_list})\n",
    "df['dts'] = pd.to_datetime(df['name_list'],format='%Y.%m.%d_%H.%M.%S',utc=True)\n",
    "df['delta_t'] = df['dts']-df['dts'].shift(1)\n",
    "df.loc[0,'delta_t'] = pd.Timedelta(0)\n",
    "\n",
    "def bin_f(row):\n",
    "    if row['delta_t'] > pd.Timedelta('20H'):\n",
    "        return row['dts'].date()\n",
    "    \n",
    "df['bin']=df.apply(bin_f,axis = 1)\n",
    "df.loc[0:1,'bin']=df.loc[0,'dts'].date()\n",
    "df['bin']=df['bin'].fillna(method='ffill')\n",
    "g_df = df.groupby('bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the average psd measured in each night window. Column names contain date at the start of the night "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_sp_psd = pd.DataFrame()\n",
    "\n",
    "for name,group in g_df:\n",
    "    df_avg_sp_psd.loc[:,str(name)] = df_sp_psd.loc[:,group['name_list'].tolist()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_sp_psd.to_csv(save_path+'avg_sp_psd_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_avg_t_psd = pd.DataFrame()\n",
    "\n",
    "for name,group in g_df:\n",
    "    df_avg_t_psd.loc[:,str(name)] = df_t_psd.loc[:,group['name_list'].tolist()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_t_psd.to_csv(save_path+'avg_t_psd_'+dstr+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit power law to avg psds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psd_results = pd.DataFrame(columns=['sp_psd_slope','sp_psd_int','sp_psd_area','t_psd_slope','t_psd_int','t_psd_area'], index = df_avg_sp_psd.columns)\n",
    "\n",
    "for i in df_avg_sp_psd.columns:\n",
    "    y = df_avg_sp_psd[i]\n",
    "    x = radialProfile(kr)\n",
    "    df_psd_results.loc[i,['sp_psd_slope','sp_psd_int']] = linear_fit(x,y,0.33,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_avg_sp_psd.columns:\n",
    "    y = df_avg_t_psd[i].dropna()\n",
    "    x = fft.fftfreq(len(y),.001)\n",
    "    df_psd_reseults.loc[i,['t_psd_slope','t_psd_int']] = linear_fit(x,y,2.0,30.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the CSV files and concatentae all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = glob.glob(data_path + \"/sp_psd_summary*.csv\")\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for file_ in allFiles[0:3]:\n",
    "    df = pd.read_csv(file_,index_col=0)\n",
    "    list_.append(df)\n",
    "\n",
    "frame = pd.concat(list_, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file2 = pd.read_csv(data_path + 'sp_psd_summary20181204.csv',index_col=0) \n",
    "txt_file2_copy = copy.copy(txt_file2)\n",
    "\n",
    "sp_psd_data = pd.DataFrame(txt_file2_copy)\n",
    "sp_psd_data['dts'] = pd.to_datetime(sp_psd_data.loc[:,'filename'].str.split('_').str.get(2) + '_' + sp_psd_data.loc[:,'filename'].str.split('_').str.get(3),\n",
    "              utc=True, format = '%Y.%m.%d_%H.%M.%S')\n",
    "\n",
    "sp_psd_data['dts'] = sp_psd_data['dts'].dt.tz_localize(pytz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_psd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, imag = 10., tau = 1., see = 2., all_cond = True):\n",
    "    \"This selects all rows of input dataframe that satisfy conditions set by the user\"\n",
    "    \n",
    "    date1 = datetime.date(year = 2014, month = 1, day =1)\n",
    "    \n",
    "    #  AO system requirements\n",
    "    cond1 = data['dts'] > date1 \n",
    "    cond2 = data['COADDS'] == 1\n",
    "    cond3 = (data['OBSMODE'] == 'H_coron')|(data['OBSMODE'] == 'Spec')\n",
    "    cond4 = data['AOFRAMES'] == 1000\n",
    "\n",
    "    #  Good seeing conditions\n",
    "    cond5 = data['IMAG'] < imag #Bright Stars\n",
    "    cond6 = data['MASSTAU'] > tau  # slow moving turbulence [ms]\n",
    "    cond7 = data['DIMMSEE'] < see  # smaller scale turbulence [\"]\n",
    "    \n",
    "    if all_cond:\n",
    "        ind = np.where(cond1 & cond2 & cond3 & cond4 & cond5 & cond6 & cond7)[0]  \n",
    "        print len(ind)\n",
    "    else:\n",
    "        ind = np.where(cond1 & cond2 & cond3 & cond4 & cond5)[0]  \n",
    "        print len(ind)\n",
    "\n",
    "    filtered_data = data.iloc[ind]\n",
    "    #filtered_data = filtered_data.dropna(subset = ['CONTR040','cal_wfe','M1_avg','TAMBIENT','Outside_OE_temperature'])\n",
    "    \n",
    "    new_ind = np.arange(len(filtered_data))\n",
    "    filtered_data = filtered_data.set_index(new_ind)\n",
    "        \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = filter_data(raw_contrast_data,all_cond=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge PSD data with IFS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_psd_raw_IFS_data =  pd.merge_asof(sp_psd_data[['slope','dts','filename','path']].sort_values('dts'),raw_contrast_data, on='dts',tolerance=pd.Timedelta('1min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_psd_raw_IFS_data = sp_psd_raw_IFS_data.dropna(subset=['slope','M1_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print sum(np.isfinite(sp_psd_raw_IFS_data['TAMBIENT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = sp_psd_raw_IFS_data.groupby(['night_number', 'OBJNAME'], as_index= False).mean().dropna(subset = ['slope','M1_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less = np.where(np.abs(grouped['M1_avg']-grouped['T_twr'])<1.)[0]\n",
    "more = np.where(np.abs(grouped['M1_avg']-grouped['T_twr'])>=1.)[0]\n",
    "\n",
    "grouped.loc[more,'slope'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "x = grouped['M1_avg']-grouped['TAMBIENT']\n",
    "y = grouped['slope']\n",
    "print(sum(np.isfinite(y)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.scatter(x,y,c='red',marker='s')\n",
    "plt.ylabel('log of Spatial PSD Slope',fontsize=15)\n",
    "plt.xlabel('Primary - Outside air [C]',fontsize=15)\n",
    "#plt.colorbar()\n",
    "\n",
    "\n",
    "#plt.savefig(save_path+'sp_psd_slope_vs_delT_grouped_20181205.pdf')\n",
    "\n",
    "\n",
    "#plt.savefig(save_path+'sp_psd_slope_vs_delT_night_20181201.pdf')\n",
    "#plt.plot(sp_psd_raw_IFS_data['slope'],'.',alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(grouped['slope'] == np.max(grouped['slope']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_dome_seeing(data, sample_size, presence = True):\n",
    "    \n",
    "    cut = 0\n",
    "    sample = set()\n",
    "    \n",
    "    if presence:\n",
    "        \n",
    "        while len(sample) <= sample_size:\n",
    "            tau0 = data.MASSTAU.sort_values(ascending = False)[0:cut]\n",
    "            mirror_to_air_temp = np.abs(data.M1_avg - data.T_twr).sort_values(ascending = False)[0:cut]\n",
    "            contrast = data.CONTR040.sort_values(ascending = False)[0:cut]\n",
    "            psd_slope = data.slope.sort_values(ascending = False)[0:cut]\n",
    "            sample = set(tau0.index) & set(mirror_to_air_temp.index) & set(contrast.index) & set(psd_slope.index)\n",
    "            cut = cut + 1\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        while len(sample) <= sample_size:\n",
    "            tau0 = data.MASSTAU.sort_values(ascending = False)[0:cut]\n",
    "            mirror_to_air_temp = np.abs(data.M1_avg - data.T_twr).sort_values()[0:cut]\n",
    "            contrast = data.CONTR040.sort_values()[0:cut]\n",
    "            psd_slope = data.slope.sort_values(ascending = True)[0:cut]\n",
    "            sample = set(tau0.index) & set(mirror_to_air_temp.index) & set(contrast.index) & set(psd_slope.index)\n",
    "            cut = cut + 1\n",
    "    return list(sample)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_psd_raw_IFS_data.loc[search_for_dome_seeing(sp_psd_raw_IFS_data,10,presence=True),\n",
    "                       ['dts','CONTR040','M1_avg','TAMBIENT','MASSTAU','slope','IMAG','filename']].sort_values(\"CONTR040\",ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_psd_raw_IFS_data.loc[search_for_dome_seeing(sp_psd_raw_IFS_data,10,presence=False),\n",
    "                       ['dts','CONTR040','M1_avg','TAMBIENT','MASSTAU','slope','filename']].sort_values(\"CONTR040\",ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
