{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aotelem\n",
    "This notebook pulls down data for raw IFS frames. Only images that were successfully processed to \"reduced data products\" are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import time\n",
    "import astropy.time as aptime\n",
    "import copy\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import gpiTools as gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = (14.0, 5.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query DB. Seeing entries will need cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querydbflag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if querydbflag:\n",
    "    import gpifilesdb\n",
    "    db = gpifilesdb.GPIFilesDB(server='127.0.0.1', username='mtallis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains data that matches up with AO telemetry. Used to calibrate the WFE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dbres' in locals():\n",
    "    del(dbres)\n",
    "        \n",
    "savedir = os.environ[\"HOME\"]+'/Dropbox (GPI)/TEST_SCRATCH/scratch/mtallis/code/'\n",
    "\n",
    "if querydbflag:\n",
    "    query = \"\"\"SELECT\n",
    "    AORAW_FILES.datafile, objname,whenstr from AORAW\n",
    "    left join AORAW_FILES on AORAW.UID = AORAW_FILES.RAWID\n",
    "    where objname not like 'Zenith' and\n",
    "    aoframes like 1000 and\n",
    "    datafile like '%_phase%' order by whenstr\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # the directory stuff at the end is b/c there are a \n",
    "    # couple duplicate folders with permutations of the same name\n",
    "    # and the data got stored in both (eg: HD 75519 and HD_75519)\n",
    "    # Get rid of the non-standard directory names\n",
    "\n",
    "\n",
    "    dbres = db._do_query(query)\n",
    "    dbdf = pd.DataFrame(dbres)\n",
    "    \n",
    "    print 'outputting dataframe to '+savedir\n",
    "    dstr = time.strftime('%Y%m%d')\n",
    "    prefix = 'aotelem_'\n",
    "    dbdf.to_excel(savedir+prefix+dstr+'.xls', index=False)\n",
    "    dbdf.to_csv(savedir+prefix+dstr+'.txt', index=False)\n",
    "\n",
    "    \n",
    "else:\n",
    "    dstr = '20190226'\n",
    "    print \"******************************************************************\"\n",
    "    print \"Loading DB query w/ dirty seeing queried on \"+dstr\n",
    "    print \"******************************************************************\"\n",
    "\n",
    "    dbdf = pd.read_csv(savedir+'aotelem_'+dstr+'.txt')\n",
    "    \n",
    "print \"There are %g entries.\\n\"%len(dbdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not link to the AO telemetry data. Only contains IFS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dbres' in locals():\n",
    "    del(dbres)\n",
    "        \n",
    "savedir = os.environ[\"HOME\"]+'/Dropbox (GPI)/TEST_SCRATCH/scratch/mtallis/code/'\n",
    "\n",
    "if querydbflag:\n",
    "    query = \"\"\"SELECT\n",
    "    RawDataProducts.DATAFILE, DATALAB, OBJNAME,\n",
    "    DATESTR, UTSTART, MJDOBS, ITIME, COADDS,\n",
    "    OBSMODE, DISPERSR, IFSFILT, AOFRAMES, AOSPATIA,\n",
    "    HMAG, STMAG as IMAG, FLUX as AOFLUX, AOWFE as RawDPwfe, \n",
    "    \n",
    "    PAR_ANG, PA, IAA, AZIMUTH, ELEVATIO, AIRMASS, AMSTART, AMEND,\n",
    "    WINDM2, WINDM2DR, WINDDIRE, WINDSPEE, TAMBIENT, OMSATEMP, GLITEMP, GLOTEMP,\n",
    "    MASSSEE, MASSTAU, DIMMSEE,\n",
    "    MASS05CN, MASS1CN2, MASS2CN2, MASS4CN2, MASS8CN2, MASS16CN, MASSISOP,    \n",
    "    \n",
    "    DRPDATE,\n",
    "    ReducedDataProducts.CONTR025, ReducedDataProducts.CONTR040, ReducedDataProducts.CONTR080\n",
    "    \n",
    "    from RawDataProducts\n",
    "    left join OBSNOTES on RawDataProducts.UID = OBSNOTES.UID\n",
    "    inner join Raw2Reduced on RawDataProducts.UID = Raw2Reduced.RAWID\n",
    "    inner join ReducedDataProducts on Raw2Reduced.REDID = ReducedDataProducts.UID\n",
    "    \n",
    "    where RawDataProducts.OBJNAME not like 'Zenith'\n",
    "    and RawDataProducts.ARTSRC like 'GPI_DEPLOY_OUT'\n",
    "    and RawDataProducts.AOCLOOP like 'TRUE'\n",
    "    and RawDataProducts.DATAFILE like 'S201%S%.fits'\n",
    "    and OBSNOTES.markedbad is NULL\n",
    "\n",
    "    and ReducedDataProducts.DATAFILE like 'S201%S%_spdc_distorcorr.fits'\n",
    "    and ReducedDataProducts.DROPBOXPATH like '%autoreduced%'\n",
    "    and ReducedDataProducts.DROPBOXPATH not like '%Non-Campaign%'\n",
    "    and ReducedDataProducts.filetype = 'Spectral Cube'\n",
    "\n",
    "    and ReducedDataProducts.DROPBOXPATH not like '%/HR_4796/%'\n",
    "    and ReducedDataProducts.DROPBOXPATH not like '%/HD 75519/%'\n",
    "    \n",
    "    order by RawDataProducts.DATAFILE , DRPDATE DESC    \n",
    "    \"\"\"\n",
    "\n",
    "    # the directory stuff at the end is b/c there are a \n",
    "    # couple duplicate folders with permutations of the same name\n",
    "    # and the data got stored in both (eg: HD 75519 and HD_75519)\n",
    "    # Get rid of the non-standard directory names\n",
    "\n",
    "\n",
    "    dbres = db._do_query(query)\n",
    "    dbdf = pd.DataFrame(dbres)\n",
    "    del(dbres)\n",
    "    dbdf['MJDOBS'] = pd.to_numeric(dbdf['MJDOBS'])\n",
    "    \n",
    "    print 'outputting dataframe to '+savedir\n",
    "    dstr = time.strftime('%Y%m%d')\n",
    "    prefix = 'IFS_AllOnSky_RawDistorcorr_'\n",
    "    dbdf.to_excel(savedir+prefix+dstr+'.xls', index=False)\n",
    "    dbdf.to_csv(savedir+prefix+dstr+'.txt', index=False)\n",
    "\n",
    "    \n",
    "else:\n",
    "    dstr = '20190226'\n",
    "    print \"******************************************************************\"\n",
    "    print \"Loading DB query w/ dirty seeing queried on \"+dstr\n",
    "    print \"******************************************************************\"\n",
    "\n",
    "    dbdf = pd.read_csv(savedir+'IFS_AllOnSky_RawDistorcorr_'+dstr+'.txt')\n",
    "    \n",
    "print \"There are %g entries.\\n\"%len(dbdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dbdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for multiply-matched raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set(dbdf['DATAFILE'])) < len(dbdf):\n",
    "    print 'number of files = '+str(len(dbdf))\n",
    "    print 'number of unique= '+str(len(set(dbdf['DATAFILE'])))\n",
    "    #raise Exception('Some raw files have multiple entries. Quitting so you can figure this out.')\n",
    "    \n",
    "    f0 = ''\n",
    "    ct = 0\n",
    "    df1 = pd.DataFrame(dbdf[ct:ct+1], index=[0])\n",
    "\n",
    "    for f in dbdf['DATAFILE']:\n",
    "        if f == f0:\n",
    "            df1 = df1.append(dbdf[ct:ct+1], ignore_index=False)\n",
    "        f0 = f\n",
    "        ct = ct+1\n",
    "\n",
    "    df1.drop(0,inplace=True) # because it was a dummy entry\n",
    "    \n",
    "    print df1[['DATAFILE','CONTR040','OBJNAME']]\n",
    "    \n",
    "    raise Exception('Duplicate raw entries. You figure out what to do.')\n",
    "\n",
    "else:\n",
    "    print 'Hurray! All raw files have only 1 reduced match.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove bad seeing values \n",
    "- 0\n",
    "- repeated for >=30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember: in DATESTR we use the UT date that covers most\n",
    "#  of the night (everthing from ~3pm local time on is recorded with the next date)\n",
    "# the \"datetimes\" reconstruction from MJD is the right one!\n",
    "\n",
    "t = aptime.Time(dbdf['MJDOBS'], format='mjd')\n",
    "#dbdf['datetime'] = t.datetime\n",
    "#dbdf[['DATESTR','UTSTART','datetime']][270:280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeing_vars = ['DIMMSEE','MASSSEE','MASSTAU','MASSISOP','MASS05CN',\\\n",
    "               'MASS1CN2','MASS2CN2','MASS4CN2','MASS4CN2','MASS8CN2','MASS16CN']\n",
    "seeing_is_invalid = {}\n",
    "for var in seeing_vars:\n",
    "    # remove repeats\n",
    "    seeing_is_invalid[var] = gpt.find_invalid_repeats(dbdf[var],t.datetime,30)\n",
    "    dbdf.loc[seeing_is_invalid[var],var] = np.nan\n",
    "    \n",
    "    # remove 0s, if present\n",
    "    try:\n",
    "        dbdf.loc[dbdf[var]==0, var] = np.nan\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbdf = dbdf.drop_duplicates(subset='DATAFILE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = os.environ[\"HOME\"]+'/Dropbox (GPI)/TEST_SCRATCH/scratch/mtallis/code/'\n",
    "prefix = 'IFS_AllOnSky_RawDistorcorr_CleanSee30_'\n",
    "#prefix = 'AO_telem_'\n",
    "dbdf.to_excel(savedir+prefix+dstr+'.xls', index=False)\n",
    "dbdf.to_csv(savedir+prefix+dstr+'.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
